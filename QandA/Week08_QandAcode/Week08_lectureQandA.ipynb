{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div align=\"center\"><font color='green'> COSC 2673/2793 | Machine Learning  </font></div>\n",
    "## <div align=\"center\"> <font color='green'> **Example: Week08 Lecture QandA**</font></div>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Demo\n",
    "\n",
    "**Disclaimer: To simplify the example this code assumes the following without any investigations**\n",
    "\n",
    "> A linear classifier is assumed to be appropriate.\n",
    "\n",
    "> Hold out test set is used instead of cros-validation even though this might not be a good stratergy. \n",
    "\n",
    "> The obhective is to demostrate how the techniques are used and not to come up with the best model.\n",
    "\n",
    "\n",
    "First lets load the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now load the dataset. Uncomment appropriate part of the code\n",
    "> Dataset 1 is a modified version of the `PIMA Indians diabetes dataset` (Missing values resolved). The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. \n",
    "\n",
    "> Dataset 2 is the 'Glaucoma' dataset where the goal is to predict if a patient has Glaucoma or not based on 63 different physiological measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiaPedigreeFunction', 'Age', 'Class']\n",
    "att_names = names[:-1]\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "dataframe.head(5)\n",
    "s_features = 8\n",
    "\n",
    "# # Dataset 2\n",
    "# dataframe = pd.read_csv('./GlaucomaM.csv')\n",
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(dataframe['Class'])\n",
    "# class_labels = le.inverse_transform([0,1])\n",
    "# dataframe['Class'] = le.transform(dataframe['Class'])\n",
    "# names = dataframe.columns\n",
    "# att_names = names[:-1]\n",
    "# dataframe.head(5)\n",
    "# s_features = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up the data into attributes and target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataframe['Class']\n",
    "X = dataframe.drop(['Class'], axis = 1)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first hold out some data for model evaluation. 70-30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TrainX, TestX, TrainY, TestY = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(TrainX)\n",
    "\n",
    "TrainX = preprocessing.scale(TrainX)\n",
    "TestX = preprocessing.scale(TestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train a simple logistic regression model that use all the features. No regularaization (C = high value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "logReg.fit(TrainX, TrainY)\n",
    "pred = logReg.predict(TestX)\n",
    "\n",
    "print(\"Test results for logistic regression with no feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods - Example\n",
    "Lets first try a filter method in sk-learn first. for this we are plannig to use chi-squared mesure to establisth the \"best\" features. The number of features to pick is set to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "\n",
    "featureSelector = SelectKBest(score_func=f_classif, k=5).fit(TrainX, TrainY)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "scores = featureSelector.scores_\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.barh(att_names, scores, )\n",
    "\n",
    "# get the selected feature vectors\n",
    "TrainX_new = featureSelector.transform(TrainX)\n",
    "TestX_new = featureSelector.transform(TestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now see how logistic regression works on selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "logReg.fit(TrainX_new, TrainY)\n",
    "pred = logReg.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with filtered feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will performance chage wit the hyper-parameter k. Would you use cross valiadation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_all = np.arange(1,s_features+1)\n",
    "f1_hold = []\n",
    "acc_hold = []\n",
    "for k in k_all:\n",
    "    featureSelector = SelectKBest(score_func=f_classif, k=k).fit(TrainX, TrainY)\n",
    "    TrainX_new = featureSelector.transform(TrainX)\n",
    "    TestX_new = featureSelector.transform(TestX)\n",
    "    \n",
    "    # Should consider CV\n",
    "    logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "    logReg.fit(TrainX_new, TrainY)\n",
    "    pred = logReg.predict(TestX_new)\n",
    "    \n",
    "    f1_hold.append(f1_score(TestY, pred))\n",
    "    acc_hold.append(accuracy_score (TestY, pred))\n",
    "\n",
    "plt.plot(k_all, f1_hold)\n",
    "plt.plot(k_all, acc_hold)\n",
    "plt.legend(['F1-score','Accuracy'])\n",
    "plt.xlabel('Number of features selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods - Example\n",
    "Next lets implement `Recursive Feature Elimination` which is a type of wrapper feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "rfe = RFE(model, 5).fit(TrainX, TrainY)\n",
    "print(\"Num Features: %s\" % (rfe.n_features_))\n",
    "sel_inx = np.ix_(rfe.support_)[0].tolist()\n",
    "print(\"Selected Features: %s\" % [att_names[i] for i in sel_inx])\n",
    "\n",
    "# get the selected feature vectors\n",
    "TrainX_new = rfe.transform(TrainX)\n",
    "TestX_new = rfe.transform(TestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now see how logistic regression works on selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "logReg.fit(TrainX_new, TrainY)\n",
    "pred = logReg.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with Recursive Feature Elimination\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded methods - Example\n",
    "Weel lets use l1 penalization. This is the Lasso penalty. Should use cross validation to set C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(penalty='l1', C=.1, max_iter=100, solver='liblinear')\n",
    "logReg.fit(TrainX, TrainY)\n",
    "pred = logReg.predict(TestX)\n",
    "\n",
    "print(\"Test results for logistic regression with l1 penalty\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "coef = pd.Series(np.squeeze(logReg.coef_), index = att_names)\n",
    "imp_coef = coef.sort_values()\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Linear Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based feature selection - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "tree_clf = ExtraTreesClassifier(n_estimators=100).fit(TrainX, TrainY)\n",
    "scores = tree_clf.feature_importances_  \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.barh(att_names, scores)\n",
    "\n",
    "model = SelectFromModel(tree_clf, prefit=True)\n",
    "TrainX_new = model.transform(TrainX)\n",
    "TestX_new = model.transform(TestX)\n",
    "print(\"Num Features: %s\" % (TrainX_new.shape[1]))\n",
    "\n",
    "tree_clf = ExtraTreesClassifier(n_estimators=100).fit(TrainX_new, TrainY)\n",
    "pred = tree_clf.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for Random forest with tree feature selection\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature construction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "components = 5\n",
    "pca = PCA(n_components=components).fit(TrainX)\n",
    "TrainX_new = pca.transform(TrainX)\n",
    "TestX_new = pca.transform(TestX)\n",
    "\n",
    "logReg = LogisticRegression(C=10000, max_iter=100, solver='liblinear')\n",
    "logReg.fit(TrainX_new, TrainY)\n",
    "pred = logReg.predict(TestX_new)\n",
    "\n",
    "print(\"Test results for logistic regression with PCA feature construction\")\n",
    "print(\"\\tF1 Score: \", f1_score(TestY, pred))\n",
    "print(\"\\tAccuracy: \", accuracy_score (TestY, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "plt.bar(np.arange(1,components+1), pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.bar(np.arange(1,components+1), pca.singular_values_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, -2:]\n",
    "Y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(X)\n",
    "X_new = pca.transform(X)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(X[:,0], X[:,1], 'ro')\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(X_new[:,0], X_new[:,1], 'ro')\n",
    "plt.xlim([-4.5,4.5])\n",
    "plt.ylim([-1.25,1.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(X[:,0], X[:,1], 'ro')\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(X_new[:,0],np.zeros_like(X_new[:,0]), 'ro')\n",
    "plt.xlim([-4.5,4.5])\n",
    "plt.ylim([-1.25,1.25])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
