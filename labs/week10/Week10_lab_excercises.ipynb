{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZzI1IC0S3ol"
   },
   "source": [
    "---\n",
    "# <div align=\"center\"><font color='green'>  </font></div>\n",
    "# <div align=\"center\"><font color='green'> COSC 2673/2793 | Machine Learning  </font></div>\n",
    "## <div align=\"center\"> <font color='green'> Week 10 Lab Exercises: **Deep Neural Networks (DL)**</font></div>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2qHa2hjS3or"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this lab you will be:\n",
    "1. Learning how to use Keras API (in tensorflow library).  \n",
    "2. Implement deep NN to classify images in the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). \n",
    "\n",
    "This lab can be run either on local machine (anaconda), AWS or Google Colab. Instruction on running a notebook on Google Colab is available at: [Instructions on using Google Colab](https://rmit.instructure.com/courses/79534/files/17891673?wrap=1). If you are on Colab, make sure you add a GPU to the notebook so that the code will run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWwcCHYGS3os"
   },
   "source": [
    "## Dataset\n",
    "We will be using the CIFAR-10 dataset we used last week with NN. \n",
    "\n",
    "\n",
    "# Reading the data\n",
    "Read the CIFAR 10 data and generate train/test/val split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvKgAKw4dAvl"
   },
   "source": [
    "**Google colab:** If you are using google colab for this lab run the following 3 blocks to load the data. Also make sure you activate the GPU using the instructions on canvas [Instructions on using Google Colab](https://rmit.instructure.com/courses/79534/files/17891673?wrap=1)\n",
    "\n",
    "**Local machine or AWS:** If on local machine or on AWS, comment the following 3 code blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22622,
     "status": "ok",
     "timestamp": 1620343587010,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "e9hhSI43cBKm",
    "outputId": "b0d2222e-1a82-41b1-fd8f-cb80917cabeb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23269,
     "status": "ok",
     "timestamp": 1620343587665,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "f3c3pWQzcFmG",
    "outputId": "e2f62c4e-610b-4006-a0fb-7fa329062d89"
   },
   "outputs": [],
   "source": [
    "# Change according to your directory structure\n",
    "!ls /content/drive/'My Drive'/COSC2673_2110/Labs/Week10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25685,
     "status": "ok",
     "timestamp": 1620343590087,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "DyZxM_01cxBn",
    "outputId": "42b2a3ff-fe84-4a82-f31f-c2a2a81c6725"
   },
   "outputs": [],
   "source": [
    "# Change according to your directory structure\n",
    "!cp /content/drive/'My Drive'/COSC2673_2110/Labs/Week10/CIFAR10_Lab9.zip .\n",
    "!unzip -q -o CIFAR10_Lab9.zip\n",
    "!rm CIFAR10_Lab9.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGhLpv5_zkkb"
   },
   "source": [
    "Running a deep CNN model on our full dataset can be time consuming. Since we are only interested in learning the basics, you can use only a subset of data. Uncomment the two lines after the comment to select a subset of data that include only cats and dogs (2 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25679,
     "status": "ok",
     "timestamp": 1620343590087,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "BV6lsU4DS3os",
    "outputId": "ebf03acd-2c25-4387-fd64-6fd37b62e8fe"
   },
   "outputs": [],
   "source": [
    "# Uncomment if on loca machine or AWS\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('./CIFAR10_Lab9.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./')\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./CIFAR_Data.csv')\n",
    "\n",
    "OUTPUT_CLASSES = 10\n",
    "\n",
    "# Uncomment the following line to do two class classification with\n",
    "# a subset of data\n",
    "# data = data[(data['Class'] == 3) | (data['Class'] == 5)]\n",
    "# OUTPUT_CLASSES = 2\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_data.shape[0], val_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaJHvJqAS3ot"
   },
   "source": [
    "Create the data generator for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26760,
     "status": "ok",
     "timestamp": 1620343591174,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "9THb0e0HS3ou",
    "outputId": "05b671bc-b21f-4c78-a1f2-e82be1cd43e8"
   },
   "outputs": [],
   "source": [
    "train_data['Class'] = train_data['Class'].astype('str')\n",
    "val_data['Class'] = val_data['Class'].astype('str')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        directory='./',\n",
    "        x_col=\"ImgPath\",\n",
    "        y_col=\"Class\",\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        directory='./',\n",
    "        x_col=\"ImgPath\",\n",
    "        y_col=\"Class\",\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoIopcoVS3ou"
   },
   "source": [
    "# Model development\n",
    "\n",
    "As discussed in Week 4-5, the typical ML model development process consists of 4 steps, lets go through each and see how it is done. \n",
    "\n",
    "1. **Determine your goals**: Performance metric and target value. Problem dependent.\n",
    "\n",
    "2. **Setup the experiment**: Setup the test/validation data, visualisers and debuggers needed to determine bottlenecks in performance (overfitting/under-fitting, feature importance).\n",
    "\n",
    "3. **Default Baseline Model**: Identify the components of end-to-end pipeline including - Baseline Models, cost functions, optimisation.\n",
    "\n",
    "4. **Make incremental changes**: Repeatedly make incremental changes such as gathering new data, adjusting hyper-parameters, or changing algorithms, based on specific findings from your instrumentation.\n",
    "\n",
    "\n",
    "### Determine your goals\n",
    "So far we conducted the EDA (task in last weeks lab) and accordingly we can decide that a performance measure such as Accuracy is adequate for this task. This is justified by the observation that there is no label imbalance in our dataset and the task is multi-class classification. According to the CIFAR website others have achieved around 82% accuracy for the full dataset. Therefore we can set that as the target performance value. However this might be unrealistic given: \n",
    "\n",
    "- We are only using a subset of data in this lab (10000/50000) to train the model. \n",
    "\n",
    "\n",
    "**For a Deep CNN the a 70% accuracy target will be more realistic.**\n",
    "\n",
    "\n",
    "### Setup the experiment\n",
    "We have also identified the train/test/val splits and ready to do the experiments. In developing a neural network, we can use the learning curves to identify the next action to take. so letâ€™s write a simple function to plot the learning curve of a NN training process. This will be our diagnostic tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26756,
     "status": "ok",
     "timestamp": 1620343591175,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "2lajUTfgS3ow"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_learning_curve(train_loss, val_loss, train_metric, val_metric, metric_name='Accuracy'):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_loss, 'r--')\n",
    "    plt.plot(val_loss, 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_metric, 'r--')\n",
    "    plt.plot(val_metric, 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdNgc7WhS3ox"
   },
   "source": [
    "### Default Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jLv6WyQS3ox"
   },
   "source": [
    "Next step is to establish a base model. There are several popular network architectures for image classification task. They include: VGG, GoogLeNet & ResNet. While ResNet is currently the most popular architecture, implementing it as a novice to NN, can be challenging. Therefore We will select the VGG network as our base model. You may later try to adapt ResNet for this task in your own time.\n",
    "\n",
    "Reference: [VGG paper](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "The VGG network was originally designed for classifying large images (with resolution around 224x224). However our images are much smaller (32x32). *Can we adapt VGG to suite our situation?*\n",
    "\n",
    "If you study the structure of the VGG, you will notice that it consists of many blocks (A block consists of: convolution + activation + pooling). Those blocks will lead to downscaling of the image due to the use of the max pooling layer. In the original VGG, there are many such blocks because the input image size is 224x224. What we can do is use only a few VGG blocks to construct the network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKYmaQQGS3oy"
   },
   "source": [
    "Lets start with a base model with only three VGG blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32236,
     "status": "ok",
     "timestamp": 1620343596659,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "EJVkNhmmS3oy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model_VGG_1 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRS3NAoeS3oy"
   },
   "source": [
    "**Observations:**\n",
    "- VGG has 3x3 convolution kernels only.\n",
    "- Pooling is always max-pooling and they are (2x2).\n",
    "- Padding is same - No boarder pixels lost when applying convolutions. \n",
    "- activation is ReLU\n",
    "\n",
    "Lets compile the model and fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32234,
     "status": "ok",
     "timestamp": 1620343596660,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "_LUV4UqdS3oz"
   },
   "outputs": [],
   "source": [
    "model_VGG_1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123710,
     "status": "ok",
     "timestamp": 1620343688140,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "SC8QbdenS3oz",
    "outputId": "49c4a641-e8d7-47f0-98dc-b93486801516"
   },
   "outputs": [],
   "source": [
    "history_VGG_1 = model_VGG_1.fit_generator(train_generator, validation_data = validation_generator, epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 123720,
     "status": "ok",
     "timestamp": 1620343688157,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "oG_LumaSS3oz",
    "outputId": "34538286-fc35-4260-e759-3fd969468aa1"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(history_VGG_1.history['loss'], history_VGG_1.history['val_loss'], \n",
    "                    history_VGG_1.history['categorical_accuracy'], history_VGG_1.history['val_categorical_accuracy'], \n",
    "                    metric_name='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0em1-YKwS3o0"
   },
   "source": [
    "What do you observe?\n",
    "\n",
    "How can you rectify the issues in the above model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJT0hvcJS3o0"
   },
   "source": [
    "### Make incremental changes\n",
    "Based on the observations we can now take appropriate actions. The above plots show that the model is overfitting. What are the appropriate actions?\n",
    "\n",
    "We can use any of the above techniques or a combination:\n",
    "- Weight regularisation\n",
    "- Dropout\n",
    "- Removing layers or reducing number of kernels (making the model simple)\n",
    "- Data Augmentation\n",
    "- Gathering more data\n",
    "- etc\n",
    "\n",
    "Let's start by applying some weight regularisation and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 123710,
     "status": "ok",
     "timestamp": 1620343688158,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "5oJftpdwS3o1"
   },
   "outputs": [],
   "source": [
    "reg_lambda = 0.001\n",
    "\n",
    "model_VGG_2 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda), input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 123703,
     "status": "ok",
     "timestamp": 1620343688159,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "Vb242u8VS3o1"
   },
   "outputs": [],
   "source": [
    "model_VGG_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 361298,
     "status": "ok",
     "timestamp": 1620343925763,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "0bk6krJ1S3o1",
    "outputId": "03646fdb-2b34-4173-95ea-c50debe7ab41"
   },
   "outputs": [],
   "source": [
    "history_VGG_2 = model_VGG_2.fit_generator(train_generator, validation_data = validation_generator, epochs=100, verbose=0)\n",
    "\n",
    "plot_learning_curve(history_VGG_2.history['loss'], history_VGG_2.history['val_loss'], \n",
    "                    history_VGG_2.history['categorical_accuracy'], history_VGG_2.history['val_categorical_accuracy'], \n",
    "                    metric_name='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_1VcPvJhBQF"
   },
   "source": [
    "**Have we solved the issue of overfitting?**\n",
    "\n",
    "If not, what can we do?\n",
    "Well we can tune the hyper-parameter reg_lambda. **This is left as an exercise for you.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm9Gse54S3o2"
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "If the model is overfitting we can use all the techniques we discussed last week to compensate for that. In addition a common technique used in deep CNN for regularisation is data augmentation. \n",
    "\n",
    "In data augmentation, we randomly perturb the original dataset to form a larger dataset and use that for training. \n",
    "\n",
    "The keras data generator can do this for us. However we need to pick the data augmentation techniques that are appropriate for the task. Lets see how this is done. We apply data augmentation only for training data (not for validation or test)\n",
    "\n",
    "> **<font color='red'><span style=\"font-size:1.5em;\">â˜ž</span> Task: Learn about available data augmentation techniques in keras [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). </font>**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361297,
     "status": "ok",
     "timestamp": 1620343925767,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "_9u5meVuS3o2",
    "outputId": "c2a6d255-4bf7-476b-b2f7-236bce25451b"
   },
   "outputs": [],
   "source": [
    "train_data['Class'] = train_data['Class'].astype('str')\n",
    "val_data['Class'] = val_data['Class'].astype('str')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last',\n",
    "                                   rotation_range=15, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, brightness_range=[0.5,1.5])\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        directory='./',\n",
    "        x_col=\"ImgPath\",\n",
    "        y_col=\"Class\",\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        directory='./',\n",
    "        x_col=\"ImgPath\",\n",
    "        y_col=\"Class\",\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 361292,
     "status": "ok",
     "timestamp": 1620343925767,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "keaB955SS3o2"
   },
   "outputs": [],
   "source": [
    "\n",
    "reg_lambda = 0.001\n",
    "\n",
    "model_VGG_3 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda), input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', \n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 361287,
     "status": "ok",
     "timestamp": 1620343925768,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "Xcr5IEKHS3o3"
   },
   "outputs": [],
   "source": [
    "model_VGG_3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 955541,
     "status": "ok",
     "timestamp": 1620344520031,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "hY-PWVZ9S3o3",
    "outputId": "8dc03b84-1e95-4525-a57a-77cd231eefc4"
   },
   "outputs": [],
   "source": [
    "history_VGG_3 = model_VGG_3.fit_generator(train_generator, validation_data = validation_generator, epochs=100, verbose=0)\n",
    "\n",
    "plot_learning_curve(history_VGG_3.history['loss'], history_VGG_3.history['val_loss'], \n",
    "                    history_VGG_3.history['categorical_accuracy'], history_VGG_3.history['val_categorical_accuracy'], \n",
    "                    metric_name='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_jO_pE-avBM"
   },
   "source": [
    "Is the target achived? How can you improve the model?\n",
    "\n",
    "Discuss with the tutor and take necessary actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szYFj2Urm5VE"
   },
   "source": [
    "### Saving the developed model\n",
    "\n",
    "Ones you are happy with the model you can save the model so that it can be used later. There are two main ways to save a model\n",
    "1. Save the entier model with the architecture configuration: `model.save()` & `model.load()`\n",
    "2. Save only the weights of each layer: `model.save_weights()` & `model.load_weights()` \n",
    "\n",
    "Let's use save for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956969,
     "status": "ok",
     "timestamp": 1620344521465,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "vXZzWtVbnd0J",
    "outputId": "864d63d8-79ba-4208-f457-f39a4e0ede54"
   },
   "outputs": [],
   "source": [
    "model_VGG_3.save(\"model_VGG_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjn0zpqin9Fr"
   },
   "source": [
    "If you are on colab you should also transfer the saved model to the google drive. Else you may loose your work when the instance gets idle and restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 957948,
     "status": "ok",
     "timestamp": 1620344522459,
     "user": {
      "displayName": "Ruwan Tennakoon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh49NLamudYtQK48uRsD0_tePqa0m-kQ9aTKVJnew=s64",
      "userId": "02479808566850363659"
     },
     "user_tz": -600
    },
    "id": "8Ph5rOAForyH"
   },
   "outputs": [],
   "source": [
    "## Only on colab\n",
    "\n",
    "# Change according to your directory structure\n",
    "!cp -R ./model_VGG_3 /content/drive/'My Drive'/COSC2673_2110/Labs/Week10/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3vyygaVpPK_"
   },
   "source": [
    "**Colab users: It is recommended that you save each intermediate model that you develop and not wait till the end to save the model.** If you save the model, then you can load it and use it, if the Colab instance gets automatically terminated or disconnected. This will prevent you from losing your work and having to do evertyhing from scratch again.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVSV1IakS3o3"
   },
   "source": [
    "# Transfer learning\n",
    "Another common approach used to develop deep CNN models is called transfer learning. \n",
    "Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task\n",
    "\n",
    "The process for transfers learning is as follows:\n",
    "- **Select Source Model:** A pre-trained source model is chosen from available models. Many research institutions release models on large and challenging datasets that may be included in the pool of candidate models from which to choose from.\n",
    "- **Reuse Model:** The model pre-trained model can then be used as the starting point for a model on the second task of interest. This may involve using all or parts of the model, depending on the modelling technique used.\n",
    "- **Tune Model:** Optionally, the model may need to be adapted or refined on the input-output pair data available for the task of interest.\n",
    "\n",
    "We will not dive into transfer learning in this lab. This will be an exercise for you. A nice tutorial on transfer learning is available at [Tensorflow tutorials](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "\n",
    "\n",
    "\n",
    "# Pre-trained models from Tensorflow\n",
    "\n",
    "Tensoflow also has a library of pre-trained models that you can use. You can get more information from [Keras Applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week10_lab_excercises.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
